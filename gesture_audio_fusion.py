import cv2
import mediapipe as mp
import pyaudio
import numpy as np
import threading
import collections
import time

# --- ÂèÉÊï∏Ë®≠ÂÆö ---
WIDTH, HEIGHT = 640, 480    # Ë¶ñÁ™óÂ§ßÂ∞è
CHUNK = 1024                # Èü≥Ë®äÁ∑©Ë°ùÂçÄ
FORMAT = pyaudio.paInt16    # 16-bit Ê†ºÂºè
CHANNELS = 1                # C270 ÊòØÂñÆËÅ≤ÈÅì
RATE = 16000                # ÂèñÊ®£Áéá
WAVE_HEIGHT = 80            # Ê≥¢ÂΩ¢ÂúñÈ´òÂ∫¶import cv2
import mediapipe as mp
import pyaudio
import numpy as np
import threading
import collections
import time

# --- ÂèÉÊï∏Ë®≠ÂÆö ---
WIDTH, HEIGHT = 640, 480    # Ë¶ñÁ™óÂ§ßÂ∞è
CHUNK = 1024                # Èü≥Ë®äÁ∑©Ë°ùÂçÄ
FORMAT = pyaudio.paInt16    # 16-bit Ê†ºÂºè
CHANNELS = 1                # C270 ÊòØÂñÆËÅ≤ÈÅì
RATE = 16000                # ÂèñÊ®£Áéá
WAVE_HEIGHT = 80            # Ê≥¢ÂΩ¢ÂúñÈ´òÂ∫¶
WAVE_Y_OFFSET = 400         # Ê≥¢ÂΩ¢Âúñ‰∏≠ÂøÉÈªû Y Â∫ßÊ®ô
WAVE_COLOR = (0, 255, 0)    # Á∂†Ëâ≤ (B, G, R)

class AudioStream:
    def __init__(self):
        self.p = pyaudio.PyAudio()
        self.stream = None
        self.running = False
        self.lock = threading.Lock()
        self.audio_buffer = collections.deque(maxlen=WIDTH)
        self.audio_buffer.extend([0] * WIDTH)
        self.device_index = self.find_c270_index()

    def find_c270_index(self):
        print("\nüîç Ê≠£Âú®ÊêúÂ∞ã Logitech C270 È∫•ÂÖãÈ¢®...")
        cnt = self.p.get_device_count()
        found = False
        idx = None
        for i in range(cnt):
            try:
                info = self.p.get_device_info_by_index(i)
                name = info.get('name')
                if ("C270" in name or "USB" in name) and info.get('maxInputChannels') > 0:
                    print(f"‚úÖ ÊâæÂà∞Ë£ùÁΩÆ Index {i}: {name}")
                    idx = i
                    found = True
                    # ÊâæÂà∞‰∏ÄÂÄãÂ∞±ÂÖàË®≠ÁÇ∫ÂÄôÈÅ∏Ôºå‰∏çË¶Å breakÔºå‰ª•ÂÖçÊúâÊõ¥Á≤æÁ¢∫ÁöÑÂåπÈÖçÔºåÊàñÊòØÁõ¥Êé•Áî®ÈÄôÂÄã
                    break 
            except Exception:
                continue
        
        if not found:
            print("‚ö†Ô∏è Êú™ÊâæÂà∞ÁâπÂÆöÈ∫•ÂÖãÈ¢®ÔºåÂ∞á‰ΩøÁî®Á≥ªÁµ±È†êË®≠Ë£ùÁΩÆ„ÄÇ")
            return None
        return idx

    def start(self):
        if self.running: return
        try:
            self.stream = self.p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                input_device_index=self.device_index,
                frames_per_buffer=CHUNK
            )
            self.running = True
            self.thread = threading.Thread(target=self._record_loop, daemon=True)
            self.thread.start()
            print("üéôÔ∏è  ËÉåÊôØÈåÑÈü≥Âü∑Ë°åÁ∑íÂ∑≤ÂïüÂãï")
        except Exception as e:
            print(f"‚ùå ÈñãÂïüÈü≥Ë®äÂ§±Êïó: {e}")

    def _record_loop(self):
        while self.running:
            try:
                data = self.stream.read(CHUNK, exception_on_overflow=False)
                int_data = np.frombuffer(data, dtype=np.int16)
                with self.lock:
                    normalized = (int_data[::2] / 150).astype(int)
                    self.audio_buffer.extend(normalized)
            except Exception as e:
                pass

    def get_waveform_points(self):
        with self.lock:
            data = list(self.audio_buffer)
        data = data[-WIDTH:]
        points = []
        for x, val in enumerate(data):
            y = WAVE_Y_OFFSET - val
            y = max(WAVE_Y_OFFSET - WAVE_HEIGHT, min(WAVE_Y_OFFSET + WAVE_HEIGHT, y))
            points.append([x, y])
        return np.array(points, np.int32)

    def stop(self):
        self.running = False
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        self.p.terminate()

def main():
    print("üöÄ Á®ãÂºèÂàùÂßãÂåñ‰∏≠...")
    audio = AudioStream()
    audio.start()

    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(
        max_num_hands=2,
        min_detection_confidence=0.7,
        min_tracking_confidence=0.5
    )

    # ÂòóË©¶ÈñãÂïüÈè°È†≠ÔºåÂ¶ÇÊûú 0 Â§±ÊïóÂ∞±Ë©¶Ë©¶ 1
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ö†Ô∏è Èè°È†≠ 0 ÁÑ°Ê≥ïÈñãÂïüÔºåÂòóË©¶Èè°È†≠ 1...")
        cap = cv2.VideoCapture(1)

    if not cap.isOpened():
        print("‚ùå ÈåØË™§ÔºöÊâæ‰∏çÂà∞‰ªª‰ΩïÊîùÂΩ±Ê©üÔºÅÁ®ãÂºèÂç≥Â∞áÁµêÊùü„ÄÇ")
        return

    cap.set(3, WIDTH)
    cap.set(4, HEIGHT)

    print("\n‚úÖ Á≥ªÁµ±ÂïüÂãïÂÆåÊàêÔºÅÊåâ 'q' ÈÄÄÂá∫„ÄÇ")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("ÁÑ°Ê≥ïËÆÄÂèñÂΩ±ÂÉèÂπÄ")
            break

        frame = cv2.flip(frame, 1)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        results = hands.process(rgb_frame)
        if results.multi_hand_landmarks:
            for landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)

        points = audio.get_waveform_points()
        if len(points) > 0:
            cv2.polylines(frame, [points], isClosed=False, color=WAVE_COLOR, thickness=2)
            cv2.line(frame, (0, WAVE_Y_OFFSET), (WIDTH, WAVE_Y_OFFSET), (100, 100, 100), 1)

        cv2.putText(frame, "C270 Audio Visualizer", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.imshow("Jetson Orin Nano - Fusion", frame)
        if cv2.waitKey(5) & 0xFF == ord('q'):
            break

    audio.stop()
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
WAVE_Y_OFFSET = 400         # Ê≥¢ÂΩ¢Âúñ‰∏≠ÂøÉÈªû Y Â∫ßÊ®ô
WAVE_COLOR = (0, 255, 0)    # Á∂†Ëâ≤ (B, G, R)

class AudioStream:
    """
    ËÉåÊôØÈåÑÈü≥È°ûÂà•ÔºöË≤†Ë≤¨Âú®Áç®Á´ãÂü∑Ë°åÁ∑í‰∏≠Êì∑ÂèñÈ∫•ÂÖãÈ¢®Êï∏Êìö
    """
    def __init__(self):
        self.p = pyaudio.PyAudio()
        self.stream = None
        self.running = False
        self.lock = threading.Lock()
        # ÈõôÂêë‰ΩáÂàóÔºåÂè™‰øùÁïôÊúÄÊñ∞ÁöÑÊï∏Êìö‰æõÁπ™ÂúñÁî®
        self.audio_buffer = collections.deque(maxlen=WIDTH)
        self.audio_buffer.extend([0] * WIDTH)
        self.device_index = self.find_c270_index()

    def find_c270_index(self):
        print("\nüîç Ê≠£Âú®ÊêúÂ∞ã Logitech C270 È∫•ÂÖãÈ¢®...")
        cnt = self.p.get_device_count()
        for i in range(cnt):
            info = self.p.get_device_info_by_index(i)
            name = info.get('name')
            # Âà§Êñ∑Ë£ùÁΩÆÂêçÁ®±
            if ("C270" in name or "USB" in name) and info.get('maxInputChannels') > 0:
                print(f"‚úÖ ÊâæÂà∞Ë£ùÁΩÆ Index {i}: {name}")
                return i
        print("‚ö†Ô∏è Êú™ÊâæÂà∞ÁâπÂÆöÈ∫•ÂÖãÈ¢®ÔºåÂ∞á‰ΩøÁî®Á≥ªÁµ±È†êË®≠Ë£ùÁΩÆ„ÄÇ")
        return None

    def start(self):
        if self.running: return
        try:
            self.stream = self.p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                input_device_index=self.device_index,
                frames_per_buffer=CHUNK
            )
            self.running = True
            self.thread = threading.Thread(target=self._record_loop, daemon=True)
            self.thread.start()
            print("üéôÔ∏è  ËÉåÊôØÈåÑÈü≥Âü∑Ë°åÁ∑íÂ∑≤ÂïüÂãï")
        except Exception as e:
            print(f"‚ùå ÈñãÂïüÈü≥Ë®äÂ§±Êïó: {e}")

    def _record_loop(self):
        while self.running:
            try:
                data = self.stream.read(CHUNK, exception_on_overflow=False)
                int_data = np.frombuffer(data, dtype=np.int16)
                
                with self.lock:
                    # Èôç‰ΩéËß£ÊûêÂ∫¶‰ª•Á¨¶ÂêàÁï´Èù¢ÂØ¨Â∫¶Ôºå‰∏¶Á∏ÆÊîæÊåØÂπÖ
                    normalized = (int_data[::2] / 150).astype(int)
                    self.audio_buffer.extend(normalized)
            except Exception as e:
                pass

    def get_waveform_points(self):
        with self.lock:
            data = list(self.audio_buffer)
        
        # ÂèñÊúÄÂæå WIDTH ÂÄãÈªû
        data = data[-WIDTH:]
        points = []
        for x, val in enumerate(data):
            y = WAVE_Y_OFFSET - val
            # ÈôêÂà∂ÁØÑÂúç
            y = max(WAVE_Y_OFFSET - WAVE_HEIGHT, min(WAVE_Y_OFFSET + WAVE_HEIGHT, y))
            points.append([x, y])
        return np.array(points, np.int32)

    def stop(self):
        self.running = False
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        self.p.terminate()

def main():
    # 1. ÂïüÂãïÈü≥Ë®ä
    audio = AudioStream()
    audio.start()

    # 2. Ë®≠ÂÆö MediaPipe
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(
        max_num_hands=2,
        min_detection_confidence=0.7,
        min_tracking_confidence=0.5
    )

    # 3. ÂïüÂãïÊîùÂΩ±Ê©ü
    cap = cv2.VideoCapture(0)
    cap.set(3, WIDTH)
    cap.set(4, HEIGHT)

    print("\nüöÄ Á®ãÂºèÂ∑≤ÂïüÂãïÔºÅÊåâ 'q' ÈÄÄÂá∫„ÄÇ")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        # Èè°ÂÉèËàáËΩâËâ≤
        frame = cv2.flip(frame, 1)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ÊâãÂã¢ÂÅµÊ∏¨
        results = hands.process(rgb_frame)
        if results.multi_hand_landmarks:
            for landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)

        # Áπ™Ë£ΩËÅ≤Ê≥¢
        points = audio.get_waveform_points()
        if len(points) > 0:
            cv2.polylines(frame, [points], isClosed=False, color=WAVE_COLOR, thickness=2)
            cv2.line(frame, (0, WAVE_Y_OFFSET), (WIDTH, WAVE_Y_OFFSET), (100, 100, 100), 1)

        # ‰ªãÈù¢Ë≥áË®ä
        cv2.putText(frame, "C270 Audio Visualizer", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.imshow("Jetson Orin Nano - Fusion", frame)
        if cv2.waitKey(5) & 0xFF == ord('q'):
            break

    audio.stop()
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()